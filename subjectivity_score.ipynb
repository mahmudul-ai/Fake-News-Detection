{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "992c823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btlab/mahmud/Fake-News-Detection/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code is running using '0'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/btlab/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/btlab/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/btlab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/btlab/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/btlab/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/btlab/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from itertools import combinations\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"The code is running using '{device}'\")\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')  # Load spaCy's English model\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load configuration from JSON file\n",
    "with open('config-biometric.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "workspace = config[\"workspace\"]\n",
    "\n",
    "col = [\"id\", \"label\", \"statement\", \"date\", \"subject\", \"speaker\", \"speaker_description\", \"state_info\", \"true_counts\", \"mostly_true_counts\", \"half_true_counts\", \"mostly_false_counts\", \"false_counts\", \"pants_on_fire_counts\", \"context\", \"justification\"]\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(workspace + 'train.csv')\n",
    "test_data = pd.read_csv(workspace + 'test.csv')\n",
    "val_data = pd.read_csv(workspace + 'valid.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1119309f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'statement', 'date', 'subject', 'speaker',\n",
       "       'speaker_description', 'state_info', 'true_counts',\n",
       "       'mostly_true_counts', 'half_true_counts', 'mostly_false_counts',\n",
       "       'false_counts', 'pants_on_fire_counts', 'context', 'justification',\n",
       "       'statement-clean', 'frequent_trigrams', 'ttr', 'exclamation_count',\n",
       "       'adjective_count', 'sentiment_label', 'sentiment_score',\n",
       "       'subjectivity_score', 'contradiction_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cafa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "subjectivity_classifier = pipeline(\"text-classification\", model=\"HCKLab/BiBert-Subjectivity\", device=device)\n",
    "def get_subjectivity(text):\n",
    "    \"\"\"\n",
    "    Classify the subjectivity of the text.\n",
    "    \"\"\"\n",
    "    result = subjectivity_classifier(text)\n",
    "    return result[0]['label'] if result else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dea2c19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9666300415992737}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_subjectivity(\"the population of Canada was estimated to be 38 million in 2024\")\n",
    "# train_data['subjectivity'] = train_data['statement'].apply(get_subjectivity)\n",
    "# train_data['subjectivity'].value_counts()\n",
    "# train_data['subjectivity'] = train_data['subjectivity'].replace({'objective': 0, 'subjective': 1})\n",
    "# train_data['subjectivity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb15c589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: Subjectivity score added\n"
     ]
    }
   ],
   "source": [
    "# # Sentiment Analysis\n",
    "\n",
    "# Load the sentiment analysis pipeline with GPU support\n",
    "# sentiment_classifier = pipeline(\"sentiment-analysis\", device=device)\n",
    "subjectivity_classifier = pipeline(\"text-classification\", model=\"HCKLab/BiBert-Subjectivity\", device=device)\n",
    "def split_sentences(text):\n",
    "    \"\"\"\n",
    "    Split the text into sentences.\n",
    "    \"\"\"\n",
    "    doc = nlp(text.lower())\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    return sentences\n",
    "\n",
    "# Define a subjectivity detection function (this should be replaced with an actual transformer-based model)\n",
    "def subjectivity_calculation(text):\n",
    "    # Placeholder for subjectivity detection using a transformer-based model\n",
    "    # This can be replaced with a fine-tuned transformer model running on GPU\n",
    "    # Classify the subjectivity of the text.\n",
    "    subj_count = 0\n",
    "    sents = split_sentences(text)\n",
    "    for sent in sents:\n",
    "        result = subjectivity_classifier(sent)\n",
    "        if result:\n",
    "            if result[0]['label'] == 'LABEL_1':  # LABEL_1 is subjective\n",
    "                subj_count += 1\n",
    "    # Calculate the subjectivity score\n",
    "    subjectivity_score = subj_count / len(sents) if len(sents) > 0 else 0\n",
    "    return subjectivity_score\n",
    "\n",
    "# Function for sentiment and subjectivity analysis\n",
    "def subjectivity_analysis(text):\n",
    "    # if clean:\n",
    "    #     text = clean_text(text)\n",
    "    # Subjectivity detection (currently a placeholder)\n",
    "    subjectivity_score = subjectivity_calculation(text)\n",
    "\n",
    "    return {\n",
    "        \"subjectivity_score\": subjectivity_score,\n",
    "    }\n",
    "\n",
    "# Apply analysis efficiently\n",
    "def analyze_dataframe(df, text_column):\n",
    "    results = df[text_column].apply(subjectivity_analysis).apply(pd.Series)\n",
    "    df[['subjectivity_score']] = results\n",
    "    return df\n",
    "\n",
    "# Apply to datasets\n",
    "train_data = analyze_dataframe(train_data, 'statement')\n",
    "test_data = analyze_dataframe(test_data, 'statement')\n",
    "val_data = analyze_dataframe(val_data, 'statement')\n",
    "\n",
    "\n",
    "# Save DataFrames and labels as CSV files\n",
    "train_data.to_csv(workspace +'train.csv', index=False)\n",
    "test_data.to_csv(workspace + 'test.csv', index=False)\n",
    "val_data.to_csv(workspace + 'valid.csv', index=False)\n",
    "\n",
    "print(\"Checkpoint: Subjectivity score added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f9f959e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subjectivity_score\n",
       "0.000000    14624\n",
       "1.000000     2956\n",
       "0.500000      546\n",
       "0.333333      134\n",
       "0.666667       56\n",
       "0.250000       22\n",
       "0.750000        7\n",
       "0.400000        6\n",
       "0.200000        6\n",
       "0.600000        4\n",
       "0.166667        2\n",
       "0.142857        1\n",
       "0.800000        1\n",
       "0.285714        1\n",
       "0.300000        1\n",
       "0.375000        1\n",
       "0.428571        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['subjectivity_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a18aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
